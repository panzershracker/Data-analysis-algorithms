{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW les 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panzershracker/Data-analysis-algorithms/blob/master/HW_les_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM6XV3IlabW_",
        "colab_type": "text"
      },
      "source": [
        "# Урок 4. Деревья решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYL_20_gabXB",
        "colab_type": "text"
      },
      "source": [
        "## Деревья решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6OcIFWiabXC",
        "colab_type": "text"
      },
      "source": [
        "В этом уроке пойдет речь еще об одном популярном методе машинного обучения - _деревьях решений_. Это семейство алгоритмов значительно отличается от линейных моделей, но применяется также в задачах классификации и регрессии.\n",
        "\n",
        "Метод основан на известной структуре данных - деревьях, которые по сути представляют собой последовательные инструкции с условиями. Например, в обсуждаемой ранее задаче кредитного скоринга может быть следующий алгоритм принятия решения:\n",
        "\n",
        "1. Старше ли клиент 18 лет? Если да, то продолжаем, иначе отказываем в кредите.\n",
        "\n",
        "2. Превышает ли его заработок 50 тысяч рублей? Если да, то продолжаем, иначе отказываем в кредите.\n",
        "\n",
        "3. Были ли у клиента просроченные кредиты ранее? Если да, отказываем в кредите, иначе выдаем.\n",
        "\n",
        "В листьях (терминальных узлах) деревьев стоят значения целевой функции (прогноз), а в узлах - условия перехода, определяющие, по какому из ребер идти. Если речь идет о бинарных деревьях (каждый узел производит ветвление на две части), обычно, если условие в узле истинно, то происходит переход по левому ребру, если ложно, то по правому. Изобразим описанный выше алгоритм в виде дерева решений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-asfUSaabXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# если дерево ниже не отображается, требуется установить библиотеку python-graphviz\n",
        "from graphviz import Digraph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aifJQkhTabXG",
        "colab_type": "code",
        "outputId": "4b1039f5-97bb-4a18-d142-53744e796ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "dot = Digraph(node_attr={'shape': 'box'})\n",
        "\n",
        "dot.node('A', label='Клиент старше 18 лет?')\n",
        "dot.node('B', label='Превышает ли его заработок 50 тысяч рублей?')\n",
        "dot.node('C', label='Отказать')\n",
        "dot.node('D', label='Были ли у клиента просроченные кредиты ранее?')\n",
        "dot.node('E', label='Отказать')\n",
        "dot.node('F', label='Отказать')\n",
        "dot.node('G', label='Выдать')\n",
        "\n",
        "dot.edge('A', 'B', label='да')\n",
        "dot.edge('A', 'C', label='нет')\n",
        "dot.edge('B', 'D', label='да')\n",
        "dot.edge('B', 'E', label='нет')\n",
        "dot.edge('D', 'F', label='да')\n",
        "dot.edge('D', 'G', label='нет')\n",
        "\n",
        "dot"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7eff91028b38>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"513pt\" height=\"305pt\"\n viewBox=\"0.00 0.00 513.00 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-301 509,-301 509,4 -4,4\"/>\n<!-- A -->\n<g id=\"node1\" class=\"node\">\n<title>A</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"443.5,-297 289.5,-297 289.5,-261 443.5,-261 443.5,-297\"/>\n<text text-anchor=\"middle\" x=\"366.5\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Клиент старше 18 лет?</text>\n</g>\n<!-- B -->\n<g id=\"node2\" class=\"node\">\n<title>B</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"416,-210 113,-210 113,-174 416,-174 416,-210\"/>\n<text text-anchor=\"middle\" x=\"264.5\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Превышает ли его заработок 50 тысяч рублей?</text>\n</g>\n<!-- A&#45;&gt;B -->\n<g id=\"edge1\" class=\"edge\">\n<title>A&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M345.3655,-260.9735C330.3216,-248.1419 309.9244,-230.7443 293.3796,-216.6326\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"295.4871,-213.8299 285.6074,-210.0034 290.9444,-219.1558 295.4871,-213.8299\"/>\n<text text-anchor=\"middle\" x=\"329.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">да</text>\n</g>\n<!-- C -->\n<g id=\"node3\" class=\"node\">\n<title>C</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"505,-210 434,-210 434,-174 505,-174 505,-210\"/>\n<text text-anchor=\"middle\" x=\"469.5\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Отказать</text>\n</g>\n<!-- A&#45;&gt;C -->\n<g id=\"edge2\" class=\"edge\">\n<title>A&#45;&gt;C</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M387.8417,-260.9735C403.0331,-248.1419 423.6303,-230.7443 440.3373,-216.6326\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"442.8046,-219.13 448.1857,-210.0034 438.2877,-213.7823 442.8046,-219.13\"/>\n<text text-anchor=\"middle\" x=\"434.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">нет</text>\n</g>\n<!-- D -->\n<g id=\"node4\" class=\"node\">\n<title>D</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"317,-123 0,-123 0,-87 317,-87 317,-123\"/>\n<text text-anchor=\"middle\" x=\"158.5\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Были ли у клиента просроченные кредиты ранее?</text>\n</g>\n<!-- B&#45;&gt;D -->\n<g id=\"edge3\" class=\"edge\">\n<title>B&#45;&gt;D</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M242.5367,-173.9735C226.9028,-161.1419 205.7058,-143.7443 188.5121,-129.6326\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.3855,-126.6422 180.4351,-123.0034 185.9445,-132.0531 190.3855,-126.6422\"/>\n<text text-anchor=\"middle\" x=\"225.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">да</text>\n</g>\n<!-- E -->\n<g id=\"node5\" class=\"node\">\n<title>E</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"406,-123 335,-123 335,-87 406,-87 406,-123\"/>\n<text text-anchor=\"middle\" x=\"370.5\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Отказать</text>\n</g>\n<!-- B&#45;&gt;E -->\n<g id=\"edge4\" class=\"edge\">\n<title>B&#45;&gt;E</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M286.4633,-173.9735C302.0972,-161.1419 323.2942,-143.7443 340.4879,-129.6326\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"343.0555,-132.0531 348.5649,-123.0034 338.6145,-126.6422 343.0555,-132.0531\"/>\n<text text-anchor=\"middle\" x=\"334.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">нет</text>\n</g>\n<!-- F -->\n<g id=\"node6\" class=\"node\">\n<title>F</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"152,-36 81,-36 81,0 152,0 152,-36\"/>\n<text text-anchor=\"middle\" x=\"116.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Отказать</text>\n</g>\n<!-- D&#45;&gt;F -->\n<g id=\"edge5\" class=\"edge\">\n<title>D&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M149.7976,-86.9735C143.9972,-74.9585 136.2642,-58.9401 129.7105,-45.3646\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"132.6908,-43.4872 125.1913,-36.0034 126.3869,-46.5305 132.6908,-43.4872\"/>\n<text text-anchor=\"middle\" x=\"147.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">да</text>\n</g>\n<!-- G -->\n<g id=\"node7\" class=\"node\">\n<title>G</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"232.5,-36 170.5,-36 170.5,0 232.5,0 232.5,-36\"/>\n<text text-anchor=\"middle\" x=\"201.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Выдать</text>\n</g>\n<!-- D&#45;&gt;G -->\n<g id=\"edge6\" class=\"edge\">\n<title>D&#45;&gt;G</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M167.4096,-86.9735C173.4058,-74.8418 181.4192,-58.6287 188.1701,-44.9698\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.3085,-46.519 192.6018,-36.0034 185.0332,-43.4173 191.3085,-46.519\"/>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">нет</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asbWiXeOabXM",
        "colab_type": "text"
      },
      "source": [
        "В задачах машинного обучения чаще всего в вершинах прописываются максимально простые условия. Обычно это сравнение значения одного из признаков $x^{j}$ с некоторым заданным порогом $t$:\n",
        "\n",
        "$$[x^{j} \\leq t].$$\n",
        "\n",
        "Если решается задача классификации, конечным прогнозом является класс или распределение вероятностей классов. В случае регрессии прогноз в листе является вещественным числом.\n",
        "\n",
        "Большим плюсом деревьев является тот факт, что они легко интерпретируемы. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNt1_4CWabXM",
        "colab_type": "text"
      },
      "source": [
        "## Построение деревьев решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR2W64axabXN",
        "colab_type": "text"
      },
      "source": [
        "Деревья обладают и отрицательными качествами - в частности, они очень легко переобучаются. Легко построить дерево, в котором каждый лист будет соответствовать одному объекту обучающей выборки. Оно будет идеально подогнано под обучающую выборку, давать стопроцентный ответ на ней, но при этом не будет восстанавливать оригинальных закономерностей, и качество ответов на новых данных будет неудовлетворительным."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k5dCHAQabXO",
        "colab_type": "text"
      },
      "source": [
        "В машинном обучении деревья строятся последовательно от корня к листьям (так называемый \"жадный\" способ). Вначале выбирается корень и критерий, по которому выборка разбивается на две. Затем то же самое делается для каждого из потомков этого корня и так далее до достаточного уровня ветвления. Задача состоит в выборе способа разбиения каждого из узлов, то есть в выборе значения порога, с которым будет сравниваться значение одного из признаков в каждом узле.\n",
        "\n",
        "Разбиение выбирается с точки зрения некоторого заранее заданного функционала качества $Q(X, j, t)$. Находятся наилучшие значения $j$ и $t$ для создания _предиката_ $[x^{j}<t]$. Параметры $j$ и $t$ можно выбирать перебором: признаков конечное число, а из всех возможных значений порога $t$ можно рассматривать только те, при которых получаются различные разбиения на две подвыборки, таким образом, различных значений параметра $t$ будет столько же, сколько различных значений признака $x^{j}$ в обучающей выборке.\n",
        "\n",
        "В каждой вершине производится проверка, не выполнилось ли некоторое условие останова (критерии останова рассмотрим далее), и если оно выполнилось, разбиение прекращается, и вершина объвляется листом, и он будет содержать прогноз.\n",
        "\n",
        "В задаче классификации это будет класс, к которому относится большая часть объектов из выборки в листе $X_{m}$\n",
        "\n",
        "$$a_{m} = \\text{argmax}_{y \\in Y} \\sum_{i \\in X_{m}}[y_{i}=y]$$\n",
        "\n",
        "или доля объектов определенного класса $k$, если требуется предсказать вероятности классов\n",
        "\n",
        "$$a_{mk} = \\frac{1}{|X_{m}|} \\sum_{i \\in X_{m}}[y_{i}=k].$$\n",
        "\n",
        "В случае регрессии можно в качестве ответа давать средний по выборке в листе\n",
        "\n",
        "$$a_{m} = \\frac{1}{|X_{m}|} \\sum_{i \\in X_{m}}y_{i}.$$\n",
        "\n",
        "После построения дерева может проводиться его _стрижка_ (pruning) - удаление некоторых вершин согласно некоторому подходу с целью понижения сложности модели и повышения обобщающей способности."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV4vq5FrabXP",
        "colab_type": "text"
      },
      "source": [
        "За функционал качества при работе с деревом решений принимается функционал вида\n",
        "\n",
        "$$Q(X_{m}, j, t) = H(X_{m}) - \\frac{|X_{l}|}{|X_{m}|}H(X_{l}) - \\frac{|X_{r}|}{|X_{m}|}H(X_{r}),$$\n",
        "\n",
        "где $X_{m}$ - множество объектов, попавших в вершину на данном шаге, $X_{l}$ и $X_{r}$ - множества, попадающие в левое и правое поддерево, соответственно, после разбиения. $H(X)$ - _критерий информативности_. Он оценивает качество распределения объектов в подмножестве и тем меньше, чем меньше разнообразие ответов в $X$, соответственно, задача обучения состоит в его минимизации и, соответственно, максимизации $Q(X_{m}, j, t)$ на данном шаге. Последний, по сути, характеризует прирост качества на данном шаге.\n",
        "\n",
        "В формуле значения критериев информативности нормируются - домножаются на долю объектов, ушедших в соответствующее подмножество. Например, если у нас множество в узле разбилось на два подмножества размером в 9990 объектов и 10 объектов, но при этом в первом подмножестве все объекты будут принадлежать к одному классу (то есть иметь минимальное значение разброса), а во втором - к разным, то в целом разбиение будет считаться хорошим, так как подавляющее большинство отсортировано правильно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjRAYZGJabXP",
        "colab_type": "text"
      },
      "source": [
        "### Критерий информативности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZfaAV7abXQ",
        "colab_type": "text"
      },
      "source": [
        "В случае регрессии разброс будет характеризоваться дисперсией, поэтому критерий информативности будет записан в виде\n",
        "\n",
        "$$H(X) = \\frac{1}{X}\\sum_{i\\in X}(y_{i} - \\bar{y}(X))^{2},$$\n",
        "\n",
        "где $\\bar{y}(X)$ - среднее значение ответа в выборке $X$:\n",
        "\n",
        "$$\\bar{y}(X) = \\frac{1}{|X|}\\sum_{i\\in X}y_{i}.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-j5hnV_abXR",
        "colab_type": "text"
      },
      "source": [
        "В задаче классификации есть несколько способов определить критерий информативности.\n",
        "\n",
        "Обозначим через $p_{k}$ долю объектов класса $k$ в выборке $X$:\n",
        "\n",
        "$$p_{k} = \\frac{1}{|X|}\\sum_{i\\in X}[y_{i} = k].$$\n",
        "\n",
        "$p_{k}$ будет характеризовать вероятность выдачи класса $k$.\n",
        "\n",
        "_Критерий Джини_ или _индекс Джини_ выглядит следующим образом:\n",
        "\n",
        "$$H(X) = \\sum^{K}_{k=1}p_{k}(1-p_{k}),$$\n",
        "\n",
        "где $K$ - количество классов в наборе данных $X$.\n",
        "\n",
        "Его минимум достигается когда все объекты в подмножестве относятся к одному классу, а максимум - при равном содержании объектов всех класов. Критерий информативности Джини можно интерпретировать как вероятность ошибки случайного классификатора.\n",
        "\n",
        "Еще один критерий информативности - _энтропийный критерий_. Он также называется _энтропией Шеннона_ и записывается как\n",
        "\n",
        "$$H(X) = - \\sum^{K}_{k=1}p_{k}\\text{log}_{2}p_{k}.$$\n",
        "\n",
        "Минимум энтропии также достигается когда все объекты относятся к одному класссу, а максимум - при равномерном распределении. Стоит отметить, что в формуле полагается, что $0\\text{log}_{2}0=0.$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQbZUf1OabXS",
        "colab_type": "text"
      },
      "source": [
        "### Критерии останова"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNr4Fc7tabXS",
        "colab_type": "text"
      },
      "source": [
        "_Критерии останова_ - это критерии, которые показывают, нужно ли остановить процесс построения дерева. Правильный выбор критериев останова роста дерева может существенно повлиять на его качество. Существует большое количество возможных ограничений:\n",
        "\n",
        "- Ограничение максимальной глубины дерева. Этот критерий считается достаточно грубым, но хорошо зарекомендовавшим себя в построении композиций деревьев - когда несколько деревьев объединяются в один алгоритм.\n",
        "\n",
        "\n",
        "- Ограничение максимального количества листьев.\n",
        "\n",
        "\n",
        "- Ограничение минимального количества $n$ объектов в листе. При этом оно должно быть достаточным, чтобы построить надежный прогноз.\n",
        "\n",
        "\n",
        "- Останов в случае, когда все объекты в листе относятся к одному классу.\n",
        "\n",
        "\n",
        "- Требование улучшения функционала качества при разбиении на какую-то минимальную величину.\n",
        "\n",
        "Подбор оптимальных критериев - сложная задача, которая обычно решается методом кросс-валидации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyLBxK_AabXT",
        "colab_type": "text"
      },
      "source": [
        "### Обрезка деревьев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvdu6ypbabXU",
        "colab_type": "text"
      },
      "source": [
        "В случае применения метода стрижки (обрезки, прунинга) деревьев использовать критерии останова необязательно, и можно строить переобученные деревья, затем снижая их сложность, удаляя листья по некоторому критерию (например, пока улучшается качество на отложенной выборке). Считается, что стрижка работает лучше, чем критерии останова."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Lc5HJnabXU",
        "colab_type": "text"
      },
      "source": [
        "Одним из методов стрижки является _cost-complexity pruning_. Допустим, мы построили дерево, обозначенное как $T_{0}$. В каждом из листьев находятся объекты одного класса, и значение функционала ошибки $R(T)$ при этом будет минимально на $T_{0}$. Для борьбы с переобучением к нему добавляют \"штраф\" за размер дерева (аналогично регуляризации, рассмотренной нами в предыдущих уроках) и получают новый функционал $R_{\\alpha}(T)$:\n",
        "\n",
        "$$R_{\\alpha}(T) = R(T) + \\alpha|T|,$$\n",
        "\n",
        "где $|T|$ - число листьев в дереве, $\\alpha$ - некоторый параметр регуляризации. Таким образом если при построении дерева на каком-то этапе построения алгоритма ошибка будет неизменна, а глубина дерева увеличиваться, итоговый функционал, состоящий из их суммы, будет расти."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSY2sT6CabXV",
        "colab_type": "text"
      },
      "source": [
        "Однако стрижка деревьев обладает существенными минусами. В частности, она является очень трудоемкой процедурой. Например, она может требовать вычисления функционала качества на валидационной выборке на каждом шаге. К тому же, на данный момент одиночные деревья на практике почти не используются, а используются композиции деревьев, и в этом случае стрижка как метод борьбы с переобучением становится еще более сложным подходом. Обычно в такой ситуации достаточно использовать простые критерии останова."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5FCRiMOabXW",
        "colab_type": "text"
      },
      "source": [
        "## CART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMNNa6u1abXX",
        "colab_type": "text"
      },
      "source": [
        "CART (Classification and regression trees) - первый из алгоритмов, состоящий в обычном последовательном построении дерева решений и придуманный в 1983 году. На первой итерации строятся все возможные разбиения исходного пространства на два и выбирается такое, при котором максимально выделен один из классов в одно подпространство. На следующих итерациях выбирается худший лист (с наибольшим разнообразием классов), и на нем проводится та же операция. Так продложается до достижения одного из критериев останова. \n",
        "\n",
        "Полученное дерево будет подогнано под обучающую выборку (переобучено), так что затем требуется его кросс-валидация или обрезка методом cost-complexity pruning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQbwzLsWabXY",
        "colab_type": "text"
      },
      "source": [
        "В качестве функции оценки качества разбиения используется критерий Джини, который также может быть записан как\n",
        "\n",
        "$$H(X) = 1 - \\sum^{K}_{k=1}p_{k}^{2}.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWm0sO22abXZ",
        "colab_type": "text"
      },
      "source": [
        "## Реализация дерева решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yZFTHXJabXa",
        "colab_type": "text"
      },
      "source": [
        "Реализуем алгоритм алгоритм работы дерева решений своими руками."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7Xi827dabXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import datasets\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FZaieu8abXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# сгенерируем данные\n",
        "classification_data, classification_labels = datasets.make_classification(n_features = 2, n_informative = 2, \n",
        "                                                      n_classes = 2, n_redundant=0, \n",
        "                                                      n_clusters_per_class=1, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "FHpOr1k6abXg",
        "colab_type": "code",
        "outputId": "09126152-0481-40d4-ced1-21c3483f3e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "source": [
        "# визуализируем сгенерированные данные\n",
        "\n",
        "colors = ListedColormap(['red', 'blue'])\n",
        "light_colors = ListedColormap(['lightcoral', 'lightblue'])\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(list(map(lambda x: x[0], classification_data)), list(map(lambda x: x[1], classification_data)), \n",
        "              c=classification_labels, cmap=colors)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7eff90f88588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAHSCAYAAAAuWvi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duu45IJUabXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Реализуем класс узла\n",
        "\n",
        "class Node:\n",
        "    \n",
        "    def __init__(self, index, t, true_branch, false_branch):\n",
        "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
        "        self.t = t  # значение порога\n",
        "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
        "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY8oNtakabXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# И класс терминального узла (листа)\n",
        "\n",
        "class Leaf:\n",
        "    \n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.prediction = self.predict()\n",
        "        \n",
        "    def predict(self):\n",
        "        # подсчет количества объектов разных классов\n",
        "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
        "        for label in self.labels:\n",
        "            if label not in classes:\n",
        "                classes[label] = 0\n",
        "            classes[label] += 1\n",
        "        #  найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
        "        prediction = max(classes, key=classes.get)\n",
        "        return prediction        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBdli3WDabXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Расчет критерия Джини\n",
        "\n",
        "def gini(labels):\n",
        "    #  подсчет количества объектов разных классов\n",
        "    classes = {}\n",
        "    for label in labels:\n",
        "        if label not in classes:\n",
        "            classes[label] = 0\n",
        "        classes[label] += 1\n",
        "    \n",
        "    #  расчет критерия\n",
        "    impurity = 1\n",
        "    for label in classes:\n",
        "        p = classes[label] / len(labels)\n",
        "        impurity -= p ** 2\n",
        "        \n",
        "    return impurity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vvLDhuRabXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Расчет качества\n",
        "\n",
        "def quality(left_labels, right_labels, current_gini):\n",
        "\n",
        "    # доля выбоки, ушедшая в левое поддерево\n",
        "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
        "    \n",
        "    return current_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhWkphi3abXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Разбиение датасета в узле\n",
        "\n",
        "def split(data, labels, index, t):\n",
        "    \n",
        "    left = np.where(data[:, index] <= t)\n",
        "    right = np.where(data[:, index] > t)\n",
        "        \n",
        "    true_data = data[left]\n",
        "    false_data = data[right]\n",
        "    true_labels = labels[left]\n",
        "    false_labels = labels[right]\n",
        "        \n",
        "    return true_data, false_data, true_labels, false_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wi8Fbs_abXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Нахождение наилучшего разбиения\n",
        "\n",
        "def find_best_split(data, labels):\n",
        "    \n",
        "    #  обозначим минимальное количество объектов в узле\n",
        "    min_leaf = 5\n",
        "\n",
        "    current_gini = gini(labels)\n",
        "\n",
        "    best_quality = 0\n",
        "    best_t = None\n",
        "    best_index = None\n",
        "    \n",
        "    n_features = data.shape[1]\n",
        "    \n",
        "    for index in range(n_features):\n",
        "        t_values = [row[index] for row in data]\n",
        "        \n",
        "        for t in t_values:\n",
        "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
        "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
        "                continue\n",
        "            \n",
        "            current_quality = quality(true_labels, false_labels, current_gini)\n",
        "            \n",
        "            #  выбираем порог, на котором получается максимальный прирост качества\n",
        "            if current_quality > best_quality:\n",
        "                best_quality, best_t, best_index = current_quality, t, index\n",
        "\n",
        "    return best_quality, best_t, best_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WqC7RNrOhJt",
        "colab_type": "text"
      },
      "source": [
        "#**Домашнее задание**\n",
        "\n",
        "### Не знаю насколько верна моя правка кода по остановке при достижении глубины = max_depth. \n",
        "\n",
        "# ==============================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1__qSXSabXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Построение дерева с помощью рекурсивной функции\n",
        "\n",
        "def build_tree(data, labels, max_depth):\n",
        "\n",
        "    quality, t, index = find_best_split(data, labels)\n",
        "\n",
        "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
        "    if quality == 0:\n",
        "        return Leaf(data, labels)\n",
        "\n",
        "        \n",
        "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
        "\n",
        "    # Кусок кода по остановке при достижении глубины = max_depth\n",
        "    for i in range(max_depth):\n",
        "      true_branch = build_tree(true_data, true_labels, max_depth)\n",
        "      false_branch = build_tree(false_data, false_labels, max_depth)\n",
        "\n",
        "\n",
        "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
        "    return Node(index, t, true_branch, false_branch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Nuws1KPS5h",
        "colab_type": "text"
      },
      "source": [
        "# ==============================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7ruKazCabX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify_object(obj, node):\n",
        "\n",
        "    #  Останавливаем рекурсию, если достигли листа\n",
        "    if isinstance(node, Leaf):\n",
        "        answer = node.prediction\n",
        "        return answer\n",
        "\n",
        "    if obj[node.index] <= node.t:\n",
        "        return classify_object(obj, node.true_branch)\n",
        "    else:\n",
        "        return classify_object(obj, node.false_branch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLOdTAqdabX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(data, tree):\n",
        "    \n",
        "    classes = []\n",
        "    for obj in data:\n",
        "        prediction = classify_object(obj, tree)\n",
        "        classes.append(prediction)\n",
        "    return classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnDPkwVJabYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Разобьем выборку на обучающую и тестовую\n",
        "\n",
        "from sklearn import model_selection\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(classification_data, \n",
        "                                                                                     classification_labels, \n",
        "                                                                                     test_size = 0.3,\n",
        "                                                                                     random_state = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbbvkqvOabYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Построим дерево по обучающей выборке\n",
        "my_tree = build_tree(train_data, train_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF1rVs9VabYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Напечатаем ход нашего дерева\n",
        "def print_tree(node, spacing=\"\"):\n",
        "\n",
        "    # Если лист, то выводим его прогноз\n",
        "    if isinstance(node, Leaf):\n",
        "        print(spacing + \"Прогноз:\", node.prediction)\n",
        "        return\n",
        "\n",
        "    # Выведем значение индекса и порога на этом узле\n",
        "    print(spacing + 'Индекс', str(node.index))\n",
        "    print(spacing + 'Порог', str(node.t))\n",
        "\n",
        "    # Рекурсионный вызов функции на положительном поддереве\n",
        "    print (spacing + '--> True:')\n",
        "    print_tree(node.true_branch, spacing + \"  \")\n",
        "\n",
        "    # Рекурсионный вызов функции на положительном поддереве\n",
        "    print (spacing + '--> False:')\n",
        "    print_tree(node.false_branch, spacing + \"  \")\n",
        "    \n",
        "print_tree(my_tree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyvzFQp3abYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Получим ответы для обучающей выборки \n",
        "train_answers = predict(train_data, my_tree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl6IyN8yabYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# И получим ответы для тестовой выборки\n",
        "answers = predict(test_data, my_tree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2odXAe7vabYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Введем функцию подсчета точности как доли правильных ответов\n",
        "def accuracy_metric(actual, predicted):\n",
        "    correct = 0\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == predicted[i]:\n",
        "            correct += 1\n",
        "    return correct / float(len(actual)) * 100.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn0L6r8CabYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Точность на обучающей выборке\n",
        "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
        "train_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D__eGtLRabYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Точность на тестовой выборке\n",
        "test_accuracy = accuracy_metric(test_labels, answers)\n",
        "test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEHbV9hXabYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Визуализируем дерево на графике\n",
        "\n",
        "def get_meshgrid(data, step=.05, border=1.2):\n",
        "    x_min, x_max = data[:, 0].min() - border, data[:, 0].max() + border\n",
        "    y_min, y_max = data[:, 1].min() - border, data[:, 1].max() + border\n",
        "    return np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))\n",
        "\n",
        "plt.figure(figsize = (16, 7))\n",
        "\n",
        "# график обучающей выборки\n",
        "plt.subplot(1,2,1)\n",
        "xx, yy = get_meshgrid(train_data)\n",
        "mesh_predictions = np.array(predict(np.c_[xx.ravel(), yy.ravel()], my_tree)).reshape(xx.shape)\n",
        "plt.pcolormesh(xx, yy, mesh_predictions, cmap = light_colors)\n",
        "plt.scatter(train_data[:, 0], train_data[:, 1], c = train_labels, cmap = colors)\n",
        "plt.title(f'Train accuracy={train_accuracy:.2f}')\n",
        "\n",
        "# график тестовой выборки\n",
        "plt.subplot(1,2,2)\n",
        "plt.pcolormesh(xx, yy, mesh_predictions, cmap = light_colors)\n",
        "plt.scatter(test_data[:, 0], test_data[:, 1], c = test_labels, cmap = colors)\n",
        "plt.title(f'Test accuracy={test_accuracy:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC48TQN9abYY",
        "colab_type": "text"
      },
      "source": [
        "Как видно, дерево строит кусочно-постоянную разделяющую гиперплоскость, то есть состоящую из прямых, параллельных осям. Чем глубже дерево, тем сложнее гиперплоскость. Также происходит и в случае регрессии - график зависимости целевого значения восстанавливается кусочно-постоянной функцией."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAYfxLSTabYZ",
        "colab_type": "text"
      },
      "source": [
        "## Работа деревьев в случае пропущенных значений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhyvKAv2abYa",
        "colab_type": "text"
      },
      "source": [
        "Иногда в реальных задачах бывает так, что не для всех объектов известно значение того или иного признака. Одним из преимуществ деревьев решений является возможность обрабатывать такие случаи.\n",
        "\n",
        "Допустим, требуется вычислить функционал качества для разбиения $[x_{j}<t]$, но в выборке $X_{m}$ для некоторого подмножества объектов $V_{j}$ неизвестно значение $j$-го признака. В этом случае функционал качества рассчитывается без учета этих объектов (обозначим выборку без их учета как $X_{m}\\text{\\ }V_{j}$), с поправкой на потерю информации:\n",
        "\n",
        "$$Q_{X_{m}, j, t} = \\frac{|X_{m}\\text{\\ } V_{j}|}{|X_{m}|}Q(X_{m}\\text{\\ }V_{j}, j,t).$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9mAVLqrabYb",
        "colab_type": "text"
      },
      "source": [
        "Если такой разбиение окажется лучшим, объекты из $V_{j}$ помещаются в оба образованных поддерева.\n",
        "\n",
        "На этапе применения дерева выполняется похожая операция. Если объект попал в вершину, в которой нельзя вычислить критерий разбиения из-за отсутствия значения необходимого признака, прогнозы для него вычисляются в обоих поддеревьях, а затем усредняются с весами, пропорциональными числу объектов в них.\n",
        "\n",
        "$$\\frac{|X_{l}|}{|X_{m}|}a_{l}(x) + \\frac{|X_{r}|}{|X_{m}|}a_{r}(x),$$\n",
        "\n",
        "где $a$ - прогноз веорятности отнесения объекта $x$ к одному из классов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMUVpzQ-abYd",
        "colab_type": "text"
      },
      "source": [
        "Кроме этого подхода существует метод построения _суррогатных предикатов_ в каждой вершине. Проще говоря, это запасной предикат, который использует другой признак, но при этом дает максимально близкое к исходному разбиение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyKBrnbpabYd",
        "colab_type": "text"
      },
      "source": [
        "## Работа деревьев с категориальными признаками"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaIif9BAabYe",
        "colab_type": "text"
      },
      "source": [
        "Кроме вещественных и бинарных признаков в задаче могут иметь место категориальные признаки (делящиеся на конечное число категорий, например, цвета автомобилей). Самый простой способ учета категориальных признаков в алгоритме деревьев состоит в разбитии вершины на столько поддеревьев, сколько имеется возможных значений признака. В этом случае дерево называется _n-арным_. Условие разбиения будет простым (отнесение признака к той или иной категории), однако здесь появляется риск получения конечного дерева с очень большим числом листьев. В случае такого дерева критерий ошибки $Q$ будет состоять из $n$ слагаемых (или из $(n+1)$) в случае максимизируемого критерия, который мы использовали."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo6IMSS-abYf",
        "colab_type": "text"
      },
      "source": [
        "Есть и другой подход, заключающийся в формировании бинарных деревьев путем разделения множества значений признака $C = \\{c_{1}, ...,c_{n}\\}$ на два непересекающихся подмножества $C_{1}$ и $C_{2}$. После такого разделения условием разбиения в узле будет проверка принадлежности признака одному из подмножеств $[x \\in C_{1}]$.\n",
        "\n",
        "Задача остается в выборе оптимального варианта разбиения исходного множества на два подмножества, так как обычный перебор всех вариантов может быть крайне затруднительным из-за большого количества вариантов разбиения. В случаях с бинарной классификацией и регрессией используют следующий метод: все возможные значения категориального признака сортируются по определенному принципу, затем заменяются на натуральные числа.\n",
        "\n",
        "В случае бинарной классификации признаки упорядочиваются не основе того, какая доля объектов с такими признаками относится к классу +1. Если обозначить множество объектов в узле $m$, у которых $j$-й признак имеет значение $с$, через $X_{m}(c)$, а через $N_{m}(c)$ количество таких объектов, получим:\n",
        "\n",
        "$$\\frac{1}{N_{m}(c_{1})} \\sum_{x \\in X_{m}(c_{1})}[y_{i}=+1]\\leq...\\leq \\frac{1}{N_{m}(c_{n})} \\sum_{x \\in X_{m}(c_{n})}[y_{i}=+1],$$\n",
        "\n",
        "и после замены категории $c_{i}$ на натуральное число ищется разбиение как для вещественного признака."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb3tpXPcabYf",
        "colab_type": "text"
      },
      "source": [
        "В случае задачи регрессии сортировка происходит схожим образом, но вместо доли объектов положительного класса среди объектов с таким значением признака вычисляется средний ответ по объектам с соответствующим значением категориального признака:\n",
        "\n",
        "$$\\frac{1}{N_{m}(c_{1})} \\sum_{x \\in X_{m}(c_{1})}y_{i}\\leq...\\leq \\frac{1}{N_{m}(c_{n})} \\sum_{x \\in X_{m}(c_{n})}y_{i}.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuInidP3abYh",
        "colab_type": "text"
      },
      "source": [
        "## Дополнительные материалы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlxrQi3-abYh",
        "colab_type": "text"
      },
      "source": [
        "1. [Энтропия](https://habr.com/ru/post/305794/)\n",
        "2. [Энтропия - теоретическое обоснование](https://ru.wikipedia.org/wiki/%D0%98%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%8D%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D0%B8%D1%8F)\n",
        "3. [Cost-Complexity Pruning](http://mlwiki.org/index.php/Cost-Complexity_Pruning)\n",
        "4. [Реализация дерева решений в функциональном стиле](https://github.com/random-forests/tutorials/blob/master/decision_tree.ipynb)\n",
        "5. [ООП-реализация дерева решений](https://github.com/curiousily/Machine-Learning-from-Scratch/blob/master/3_decision_trees.ipynb)\n",
        "6. [Пример работы дерева решений в задаче регрессии](https://habr.com/ru/company/ods/blog/322534/#derevo-resheniy-v-zadache-regressii)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-twgM3HabYj",
        "colab_type": "text"
      },
      "source": [
        "## Домашнее задание\n",
        "\n",
        "1. Реализовать дерево для задачи регрессии. Взять за основу дерево, реализованное на уроке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений."
      ]
    }
  ]
}